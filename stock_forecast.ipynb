{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stock_forecast.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPqOKy2g40ufma6wMMK/IUr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clearpoem/practice/blob/main/stock_forecast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kUSWCLwj_xyq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "path=\"/content/sample_data/\"\n",
        "os.chdir(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def get_local_data(file_name, test_split, feature_dim, sc):\n",
        "    \"\"\"本地获得训练数据和测试数据\"\"\"\n",
        "    df = pd.read_csv(file_name, encoding='gbk')  # 原始文件前面feature_dim列只保存所需要作为输入的特征\n",
        "    len_data = len(df)\n",
        "    len_train_data = int(len_data * (1 - test_split))\n",
        "    train_data_ori = df.iloc[:len_train_data, :feature_dim].values  # 按比例切割训练数据和测试数据\n",
        "    test_data_ori = df.iloc[len_train_data:len_data, :feature_dim].values\n",
        "    # 把训练数据和测试数据分别归一化\n",
        "    train_data = sc.fit_transform(train_data_ori)\n",
        "    test_data = sc.transform(test_data_ori)\n",
        "    return train_data, test_data\n",
        "\n",
        "\n",
        "def get_online_data():\n",
        "    \"\"\"线上获得训练数据和测试数据\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "def make_data_set(train_data, test_data, len_seq, feature_dim):\n",
        "    \"\"\"制作训练集和测试集\"\"\"\n",
        "\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    x_test = []\n",
        "    y_test = []\n",
        "    # 制作训练集\n",
        "    for i in range(0, len(train_data) - len_seq):\n",
        "        x_train.append(train_data[i:i + len_seq])\n",
        "\n",
        "        y_train.append(train_data[i + len_seq, feature_dim-1])\n",
        "    # 打乱训练集数据\n",
        "    np.random.seed(7)\n",
        "    np.random.shuffle(x_train)\n",
        "    np.random.seed(7)\n",
        "    np.random.shuffle(y_train)\n",
        "    tf.random.set_seed(7)\n",
        "    # 设置成array格式\n",
        "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "    # 设置成lstm输入格式\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], len_seq, feature_dim))\n",
        "    # 制作测试集\n",
        "    for i in range(0, len(test_data) - len_seq):\n",
        "        x_test.append(test_data[i:i + len_seq])\n",
        "        y_test.append(test_data[i + len_seq, feature_dim-1])\n",
        "\n",
        "    x_test, y_test = np.array(x_test), np.array(y_test)\n",
        "    x_test = np.reshape(x_test, (x_test.shape[0], len_seq, feature_dim))\n",
        "    print(\"数据集制作完毕！\")\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "def get_real_and_pre_data(sc, test_data, len_seq, fea_dim, model, x_test):\n",
        "    real_data = []\n",
        "    # 获得原始数据\n",
        "    test_data = sc.inverse_transform(test_data)\n",
        "    for i in range(0, len(test_data) - len_seq):\n",
        "        real_data.append(test_data[i + len_seq, fea_dim-1])\n",
        "    # 预测结果\n",
        "    predict_data = model.predict(x_test)\n",
        "    # 修改格式和测试集一致\n",
        "    temp = predict_data\n",
        "    for i in range(0, fea_dim-1):\n",
        "        predict_data = np.column_stack((predict_data, temp))\n",
        "    #  执行反归一化并获取最后一列\n",
        "    predict_data = sc.inverse_transform(predict_data)[:, fea_dim-1]\n",
        "    return real_data, predict_data\n",
        "\n",
        "\n",
        "def show_loss(history):\n",
        "    \"\"\"loss可视化\"\"\"\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    plt.plot(loss, label='Training Loss')\n",
        "    plt.plot(val_loss, label='Validation Loss')\n",
        "    plt.title('train and val loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_acc(real_data, pre_data):\n",
        "    \"\"\"计算展示准确率\"\"\"\n",
        "    acc1_num = 0\n",
        "    acc2_num = 0\n",
        "    acc3_num = 0\n",
        "    for i in range(0, len(real_data)):\n",
        "        threshold1 = real_data[i] * 0.0005\n",
        "        threshold2 = real_data[i] * 0.001\n",
        "        threshold3 = real_data[i] * 0.01\n",
        "        if abs(real_data[i] - pre_data[i]) < threshold1:\n",
        "            acc1_num += 1\n",
        "        if abs(real_data[i] - pre_data[i]) < threshold2:\n",
        "            acc2_num += 1\n",
        "        if abs(real_data[i] - pre_data[i]) < threshold3:\n",
        "            acc3_num += 1\n",
        "    acc1 = acc1_num/len(real_data)\n",
        "    acc2 = acc2_num / len(real_data)\n",
        "    acc3 = acc3_num / len(real_data)\n",
        "    print(\"准确率(0.00005):%f\" % acc1)\n",
        "    print(\"准确率(0.001):%f\" % acc1)\n",
        "    print(\"准确率(0.01):%f\" % acc1)\n",
        "    print(\"准确率计算完毕！\")\n",
        "\n",
        "\n",
        "def show_test_res(real_data, pre_data):\n",
        "    \"\"\"测试效果可视化\"\"\"\n",
        "    plt.plot(pre_data, color='red', label=\"pre_price\")\n",
        "    plt.plot(real_data, color='blue', label=\"real_price\")\n",
        "    plt.title(\"stoce_price_forecast\")\n",
        "    plt.xlabel('Trading_Day')\n",
        "    plt.ylabel('Price')\n",
        "    print(\"预测效果图绘制完毕！\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def get_weights(model):\n",
        "    \"\"\"参数提取\"\"\"\n",
        "    file = open(\"./wights.txt\", 'w')\n",
        "    for v in model.trainable_variables:\n",
        "        file.write(str(v.name)+'\\n')\n",
        "        file.write(str(v.shape) + '\\n')\n",
        "        file.write(str(v.numpy()) + '\\n')\n",
        "    print(\"参数提取完毕！\")\n",
        "    file.close()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    pass\n",
        "\n",
        "    # print(len(x))\n",
        "    # print(len(y))\n",
        "    # print(x)\n",
        "    # print(y)\n"
      ],
      "metadata": {
        "id": "BRX3aVcL4ibL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "def build_model(x_train, y_train, batch_size, epochs, validation_data):\n",
        "    \"\"\"建立模型并训练\"\"\"\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            LSTM(60, return_sequences=True),\n",
        "            # Dropout(0.2),\n",
        "            LSTM(50),\n",
        "            # Dropout(0.2),\n",
        "            Dense(1)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='mae',\n",
        "        metrics='acc'\n",
        "    )\n",
        "    print(\"模型建立完毕,开始训练...\")\n",
        "    # 设置回调函数\n",
        "    check_save_path = \"./stock_LSTM.ckpt\"\n",
        "    callback = [\n",
        "        # EarlyStopping(monitor='loss', patience=5),\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "            filepath=check_save_path,\n",
        "            save_best_only=True,\n",
        "            monitor='loss'\n",
        "        )\n",
        "    ]\n",
        "    history = model.fit(x_train, y_train, batch_size=batch_size,\n",
        "                        epochs=epochs, validation_data=validation_data,\n",
        "                        callbacks=callback\n",
        "                        )\n",
        "    print(\"模型训练完毕！\")\n",
        "    return model, history\n",
        "\n",
        "\n",
        "def save_model(model, code):\n",
        "    \"\"\"以股票代码为名保存模型\"\"\"\n",
        "    save_path = \"./%s.h5\" % code\n",
        "    model.save(save_path)\n",
        "    print(\"模型保存完毕！\")\n",
        "\n",
        "\n",
        "def load_models(code):\n",
        "    \"\"\"以股票代码加载模型\"\"\"\n",
        "    print(\"模型加载中....！\")\n",
        "    save_path = \"./data/%s.h5\" % code\n",
        "    model = load_model(save_path)\n",
        "    print(\"s%模型加载完毕！\" % code)\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1Fshb0Qm4iUV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "模型训练主函数\n",
        "\"\"\"\n",
        "import my_model as ml\n",
        "import data_process as dp\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 1、获取数据\n",
        "    os.chdir(\"./data\")\n",
        "    file_name = \"600021-short.csv\"\n",
        "    code = file_name[:6]\n",
        "    test_split = 0.2\n",
        "    feature_dim = 4\n",
        "\n",
        "    # 数据归一化\n",
        "    sc = MinMaxScaler(feature_range=(0, 1))\n",
        "    train_data, test_data = dp.get_local_data(file_name, test_split, feature_dim, sc)\n",
        "    # 2、制作数据集\n",
        "    len_seq = 5\n",
        "    x_train, y_train, x_test, y_test = dp.make_data_set(train_data, test_data,\n",
        "                                                        len_seq, feature_dim,)\n",
        "    # 3、创建模型训练数据\n",
        "    batch_size = 8\n",
        "    epochs = 10\n",
        "    model, history = ml.build_model(x_train, y_train, batch_size, epochs, (x_test, y_test))\n",
        "    # 保存模型\n",
        "    ml.save_model(model, code)\n",
        "    # 画出预测图\n",
        "    real_data, pre_data = dp.get_real_and_pre_data(sc, test_data, len_seq, feature_dim, model, x_test)\n",
        "    dp.show_test_res(real_data, pre_data)\n",
        "    # 输出准确率\n",
        "    dp.show_acc(real_data, pre_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f-vl7Wgnegbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qHfelLaLegZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PsZALIhBegWZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}